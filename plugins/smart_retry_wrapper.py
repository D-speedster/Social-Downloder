"""
Smart Retry Wrapper
Ø³ÛŒØ³ØªÙ… retry Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ù¾Ø³Ù†Ø¯ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§

Ø§ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„ wrapper function Ø±Ø§ Ø¨Ø±Ø§ÛŒ handle_universal_link ÙØ±Ø§Ù‡Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯
Ú©Ù‡ retry logic Ø¨Ø§ timing Ù…Ø´Ø®Øµ Ùˆ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ù¾Ø³Ù†Ø¯ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
"""
import asyncio
import time
import logging
from typing import Callable, Tuple
from pyrogram import Client
from pyrogram.types import Message

logger = logging.getLogger('smart_retry_wrapper')

# Import metrics system
try:
    from plugins.retry_metrics import retry_metrics
    METRICS_ENABLED = True
    logger.info("Retry metrics system enabled")
except ImportError:
    METRICS_ENABLED = False
    logger.warning("Retry metrics system not available")

# Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ù¾Ø³Ù†Ø¯
MESSAGES = {
    'initial': "ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„ÛŒÙ†Ú© {platform}...",
    'busy': "Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ Ø±Ø¨Ø§Øª Ù…Ø´ØºÙˆÙ„ Ø§Ø³Øª Ù„Ø·ÙØ§ Ú©Ù…ÛŒ ØµØ¨Ø± Ú©Ù†ÛŒØ¯ â˜ºï¸",
    'final_error': (
        "Ú©Ø§Ø±Ø¨Ø± Ú¯Ø±Ø§Ù…ÛŒ Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ Ù…Ø§ Ø¨Ø§ Ù…Ø´Ú©Ù„ Ø±ÙˆØ¨Ø±Ùˆ Ø´Ø¯Ù‡ Ø§Ø³Øª!\n\n"
        "Ø¯Ø± Ú©Ù…ØªØ±ÛŒÙ† Ø²Ù…Ø§Ù† Ù…Ù…Ú©Ù† ÙØ§ÛŒÙ„ Ø´Ù…Ø§ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§ Ø§Ø±Ø³Ø§Ù„ Ø®ÙˆØ§Ù‡ÛŒÙ… Ú©Ø±Ø¯"
    )
}


def categorize_error(error: Exception) -> str:
    """
    Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®Ø·Ø§ Ø¨Ø±Ø§ÛŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø¯Ø± Ù…ÙˆØ±Ø¯ retry
    
    Args:
        error: Exception object
    
    Returns:
        'transient': Ù‚Ø§Ø¨Ù„ retry Ø®ÙˆØ¯Ú©Ø§Ø±
        'permanent': Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¯Ø®Ø§Ù„Øª Ø§Ø¯Ù…ÛŒÙ†
        'system': Ø®Ø·Ø§ÛŒ Ø³ÛŒØ³ØªÙ…ÛŒ Ø¯Ø§Ø®Ù„ÛŒ
    """
    error_str = str(error).lower()
    
    # Transient errors (Ù‚Ø§Ø¨Ù„ retry)
    transient_indicators = [
        'timeout', 'timed out',
        '429', 'rate limit', 'too many requests',
        '503', 'service unavailable',
        '502', 'bad gateway',
        '504', 'gateway timeout',
        'connection', 'network',
        'temporary', 'Ù…ÙˆÙ‚Øª'
    ]
    
    for indicator in transient_indicators:
        if indicator in error_str:
            logger.info(f"Categorized as transient error: {indicator}")
            return 'transient'
    
    # Permanent errors (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ†)
    permanent_indicators = [
        '403', 'forbidden',
        '404', 'not found',
        'invalid url', 'Ù„ÛŒÙ†Ú© Ù†Ø§Ù…Ø¹ØªØ¨Ø±',
        'quota exceeded', 'Ù…Ø­Ø¯ÙˆØ¯ÛŒØª',
        'private', 'Ø®ØµÙˆØµÛŒ',
        'restricted', 'Ù…Ø­Ø¯ÙˆØ¯'
    ]
    
    for indicator in permanent_indicators:
        if indicator in error_str:
            logger.info(f"Categorized as permanent error: {indicator}")
            return 'permanent'
    
    # System errors
    system_indicators = [
        'database', 'Ø¯ÛŒØªØ§Ø¨ÛŒØ³',
        'file system', 'ÙØ§ÛŒÙ„ Ø³ÛŒØ³ØªÙ…',
        'memory', 'Ø­Ø§ÙØ¸Ù‡',
        'disk', 'Ø¯ÛŒØ³Ú©'
    ]
    
    for indicator in system_indicators:
        if indicator in error_str:
            logger.warning(f"Categorized as system error: {indicator}")
            return 'system'
    
    # Default to transient for unknown errors
    logger.info(f"Unknown error type, defaulting to transient: {error_str[:100]}")
    return 'transient'


async def smart_retry_wrapper(
    client: Client,
    message: Message,
    url: str,
    platform: str,
    original_handler: Callable,
    max_attempts: int = 3,
    retry_schedule: list = None
) -> Tuple[bool, str]:
    """
    Wrapper function Ú©Ù‡ retry logic Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø±Ø§ Ø¨Ù‡ handler Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    
    Ø§ÛŒÙ† wrapper:
    - 1 Ø«Ø§Ù†ÛŒÙ‡ ØªØ§Ø®ÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡ Ø¯Ø§Ø±Ø¯
    - Ø¨Ø§ schedule Ù…Ø´Ø®Øµ (0s, 10s, 40s) retry Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    - Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ù¾Ø³Ù†Ø¯ Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
    - Ù…ÙˆÙÙ‚ÛŒØª/Ø´Ú©Ø³Øª Ø±Ø§ ØªØ´Ø®ÛŒØµ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
    - Ø¯Ø± ØµÙˆØ±Øª Ø´Ú©Ø³Øª Ù†Ù‡Ø§ÛŒÛŒØŒ Ø¨Ù‡ ØµÙ Ø§Ø¯Ù…ÛŒÙ† Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    
    Args:
        client: Pyrogram client instance
        message: User's message object
        url: Download URL
        platform: Platform name (Instagram, TikTok, etc.)
        original_handler: Original handle_universal_link function
        max_attempts: Maximum number of retry attempts (default: 3)
        retry_schedule: List of delays in seconds [0, 10, 40] (default)
    
    Returns:
        Tuple[bool, str]: (success, message)
            - success: True if download succeeded, False if failed
            - message: Status message
    """
    user_id = message.from_user.id
    
    # Default retry schedule: [0s, 10s, 40s]
    if retry_schedule is None:
        retry_schedule = [0, 10, 40]
    
    # Ensure we have enough delays for all attempts
    while len(retry_schedule) < max_attempts:
        # Add exponential backoff for additional attempts
        last_delay = retry_schedule[-1]
        retry_schedule.append(last_delay + 30)
    
    logger.info(
        f"Starting smart retry for user {user_id}, platform {platform}, "
        f"max_attempts={max_attempts}, schedule={retry_schedule[:max_attempts]}"
    )
    
    # Ø­Ø°Ù Ù¾ÛŒØ§Ù… Ø§ÙˆÙ„ÛŒÙ‡ - handler Ø§ØµÙ„ÛŒ Ø®ÙˆØ¯Ø´ Ù¾ÛŒØ§Ù… Ù…ÛŒâ€ŒÙØ±Ø³ØªØ¯
    # Ø§ÛŒÙ† Ø§Ø² duplicate message Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    status_msg = None
    
    # ØªØ§Ø®ÛŒØ± Ø§ÙˆÙ„ÛŒÙ‡ 1 Ø«Ø§Ù†ÛŒÙ‡ (Ø·Ø¨Ù‚ requirement 1.2)
    await asyncio.sleep(1.0)
    
    last_error = None
    last_error_message = ""
    
    # ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ÛŒ retry
    for attempt in range(max_attempts):
        attempt_number = attempt + 1
        delay = retry_schedule[attempt]
        
        logger.info(
            f"Attempt {attempt_number}/{max_attempts} for user {user_id}, "
            f"platform {platform}, delay={delay}s"
        )
        
        # Ø§Ú¯Ø± Ø§ÛŒÙ† ØªÙ„Ø§Ø´ Ø§ÙˆÙ„ Ù†ÛŒØ³ØªØŒ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†
        if attempt > 0:
            # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… "Ø³Ø±ÙˆØ±Ù‡Ø§ Ù…Ø´ØºÙˆÙ„ Ø§Ø³Øª" (Ø·Ø¨Ù‚ requirement 2.1)
            if status_msg:
                try:
                    await status_msg.edit_text(MESSAGES['busy'])
                except Exception as e:
                    logger.warning(f"Failed to update status message: {e}")
            
            # Ø§Ù†ØªØ¸Ø§Ø± Ø·Ø¨Ù‚ schedule
            if delay > 0:
                logger.info(f"Waiting {delay}s before attempt {attempt_number}")
                await asyncio.sleep(delay)
        
        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯
        try:
            start_time = time.time()
            
            # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ handler Ø§ØµÙ„ÛŒ
            # ØªÙˆØ¬Ù‡: handler Ø§ØµÙ„ÛŒ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ ØµÙˆØ±Øª async Ø¨Ø§Ø´Ø¯
            await original_handler(client, message, is_retry=True)
            
            elapsed = time.time() - start_time
            
            # Ø§Ú¯Ø± Ø¨Ù‡ Ø§ÛŒÙ†Ø¬Ø§ Ø±Ø³ÛŒØ¯ÛŒÙ…ØŒ ÛŒØ¹Ù†ÛŒ Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯Ù‡
            logger.info(
                f"Success on attempt {attempt_number}/{max_attempts} "
                f"for user {user_id}, platform {platform}, "
                f"elapsed={elapsed:.2f}s"
            )
            
            # Log metrics
            if METRICS_ENABLED:
                retry_metrics.log_attempt(
                    attempt_number=attempt_number,
                    success=True,
                    platform=platform,
                    duration=elapsed
                )
            
            # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… ÙˆØ¶Ø¹ÛŒØª
            if status_msg:
                try:
                    await status_msg.delete()
                except Exception:
                    pass
            
            return True, f"Success on attempt {attempt_number}"
        
        except Exception as e:
            last_error = e
            last_error_message = str(e)
            elapsed = time.time() - start_time
            
            logger.warning(
                f"Attempt {attempt_number}/{max_attempts} failed "
                f"for user {user_id}, platform {platform}, "
                f"elapsed={elapsed:.2f}s, error={last_error_message[:200]}"
            )
            
            # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®Ø·Ø§
            error_category = categorize_error(e)
            
            # Log metrics
            if METRICS_ENABLED:
                retry_metrics.log_attempt(
                    attempt_number=attempt_number,
                    success=False,
                    platform=platform,
                    duration=elapsed,
                    error_category=error_category
                )
            
            # Ø§Ú¯Ø± Ø®Ø·Ø§ permanent Ø§Ø³Øª Ùˆ Ø§ÛŒÙ† Ø§ÙˆÙ„ÛŒÙ† ØªÙ„Ø§Ø´ Ù†ÛŒØ³ØªØŒ Ø¯ÛŒÚ¯Ø± retry Ù†Ú©Ù†
            if error_category == 'permanent' and attempt > 0:
                logger.info(
                    f"Permanent error detected on attempt {attempt_number}, "
                    f"stopping retries"
                )
                break
            
            # Ø§Ú¯Ø± Ø§ÛŒÙ† Ø¢Ø®Ø±ÛŒÙ† ØªÙ„Ø§Ø´ Ù†ÛŒØ³ØªØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯Ù‡
            if attempt < max_attempts - 1:
                continue
    
    # Ø§Ú¯Ø± Ø¨Ù‡ Ø§ÛŒÙ†Ø¬Ø§ Ø±Ø³ÛŒØ¯ÛŒÙ…ØŒ ÛŒØ¹Ù†ÛŒ Ù‡Ù…Ù‡ ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯Ù‡
    logger.error(
        f"All {max_attempts} attempts failed for user {user_id}, "
        f"platform {platform}, last_error={last_error_message[:200]}"
    )
    
    # Log final failure metrics
    if METRICS_ENABLED:
        retry_metrics.log_final_failure(platform)
    
    # Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø®Ø·Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± (Ø·Ø¨Ù‚ requirement 5.1, 5.2, 5.3)
    # Ø§Ú¯Ø± status_msg ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª (Ú†ÙˆÙ† handler Ø§ØµÙ„ÛŒ Ø®ÙˆØ¯Ø´ Ù¾ÛŒØ§Ù… Ù…ÛŒâ€ŒÙØ±Ø³ØªØ¯)ØŒ Ù¾ÛŒØ§Ù… Ø¬Ø¯ÛŒØ¯ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†
    try:
        if status_msg:
            await status_msg.edit_text(MESSAGES['final_error'])
        else:
            await message.reply_text(MESSAGES['final_error'])
    except Exception as e:
        logger.warning(f"Failed to send final error message: {e}")
    
    # Ø§ÙØ²ÙˆØ¯Ù† Ø¨Ù‡ ØµÙ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙˆØ³Ø· Ø§Ø¯Ù…ÛŒÙ†
    try:
        from plugins.failed_request_queue import FailedRequestQueue
        from plugins.db_wrapper import DB
        
        db = DB()
        queue = FailedRequestQueue(db)
        
        request_id = queue.add_request(
            user_id=user_id,
            url=url,
            platform=platform,
            error_message=last_error_message[:500],  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø·ÙˆÙ„ Ù¾ÛŒØ§Ù…
            original_message_id=message.message_id
        )
        
        if request_id > 0:
            logger.info(
                f"Added failed request to queue: request_id={request_id}, "
                f"user={user_id}, platform={platform}"
            )
            
            # Log queue addition metrics
            if METRICS_ENABLED:
                retry_metrics.log_queue_addition()
            
            # Ø§Ø±Ø³Ø§Ù„ notification Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ†
            try:
                from plugins.admin_notification import send_admin_notification
                
                await send_admin_notification(
                    client=client,
                    request_id=request_id,
                    user_id=user_id,
                    url=url,
                    platform=platform,
                    error_message=last_error_message[:500]
                )
                
                logger.info(f"Admin notification sent for request {request_id}")
            except Exception as notify_error:
                logger.error(f"Failed to send admin notification: {notify_error}")
        else:
            logger.error(f"Failed to add request to queue for user {user_id}")
    
    except Exception as queue_error:
        logger.error(f"Error adding to queue: {queue_error}")
    
    return False, f"Failed after {max_attempts} attempts: {last_error_message}"


logger.info("SmartRetryWrapper module loaded")
