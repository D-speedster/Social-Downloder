"""
Final Test Report Generator
Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ ØªØ³Øªâ€ŒÙ‡Ø§
"""

import json
import os
from datetime import datetime
from pathlib import Path

class FinalReportGenerator:
    def __init__(self):
        self.test_files = [
            'final_integration_test_results.json',
            'bot_integration_test_results.json', 
            'performance_test_results.json',
            'error_handling_test_results.json'
        ]
        self.report_data = {}
        
    def load_test_results(self):
        """Load all test result files"""
        print("ğŸ“Š Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†ØªØ§ÛŒØ¬ ØªØ³Øªâ€ŒÙ‡Ø§...")
        
        for test_file in self.test_files:
            if os.path.exists(test_file):
                try:
                    with open(test_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        test_name = test_file.replace('_test_results.json', '').replace('_results.json', '')
                        self.report_data[test_name] = data
                        print(f"  âœ… {test_file} Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
                except Exception as e:
                    print(f"  âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ {test_file}: {e}")
            else:
                print(f"  âš ï¸ ÙØ§ÛŒÙ„ {test_file} ÛŒØ§ÙØª Ù†Ø´Ø¯")
    
    def analyze_integration_tests(self):
        """Analyze integration test results"""
        integration_data = self.report_data.get('final_integration', {})
        # Check both 'results' and 'tests' keys for different test result formats
        results = integration_data.get('results', integration_data.get('tests', {}))
        
        analysis = {
            'total_tests': len(results),
            'passed_tests': sum(1 for r in results.values() if r.get('status') in ['success', 'PASS']),
            'failed_tests': sum(1 for r in results.values() if r.get('status') in ['failed', 'FAIL']),
            'skipped_tests': sum(1 for r in results.values() if r.get('status') in ['skipped', 'SKIP']),
            'success_rate': 0,
            'critical_issues': [],
            'recommendations': []
        }
        
        if analysis['total_tests'] > 0:
            analysis['success_rate'] = (analysis['passed_tests'] / analysis['total_tests']) * 100
        
        # Identify critical issues
        for test_name, result in results.items():
            if result.get('status') in ['failed', 'FAIL']:
                error_msg = result.get('error', result.get('details', {}).get('error', 'Unknown error'))
                analysis['critical_issues'].append({
                    'test': test_name,
                    'error': error_msg,
                    'severity': 'high' if 'error_handling' in test_name.lower() else 'medium'
                })
        
        # Generate recommendations
        if analysis['success_rate'] < 90:
            analysis['recommendations'].append("Ø¨Ù‡Ø¨ÙˆØ¯ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø³ÛŒØ³ØªÙ… - Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª Ú©Ù…ØªØ± Ø§Ø² 90%")
        
        if any('network' in issue['error'].lower() for issue in analysis['critical_issues']):
            analysis['recommendations'].append("Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø´Ø¨Ú©Ù‡")
            
        return analysis
    
    def analyze_bot_integration(self):
        """Analyze bot integration test results"""
        bot_data = self.report_data.get('bot_integration', {})
        results = bot_data.get('results', {})
        
        analysis = {
            'total_tests': len(results),
            'passed_tests': sum(1 for r in results.values() if r.get('status') == 'success'),
            'success_rate': 0,
            'async_issues': [],
            'recommendations': []
        }
        
        if analysis['total_tests'] > 0:
            analysis['success_rate'] = (analysis['passed_tests'] / analysis['total_tests']) * 100
        
        # Check for async-related issues
        for test_name, result in results.items():
            if result.get('status') == 'failed' and 'async' in result.get('error', '').lower():
                analysis['async_issues'].append(test_name)
        
        # Generate recommendations
        if analysis['success_rate'] == 100:
            analysis['recommendations'].append("Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¹Ø§Ù„ÛŒ - ØªÙ…Ø§Ù… ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø±Ø¨Ø§Øª Ù…ÙˆÙÙ‚")
        elif analysis['async_issues']:
            analysis['recommendations'].append("Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª async/await Ø¯Ø± Ø±Ø¨Ø§Øª")
            
        return analysis
    
    def analyze_performance_tests(self):
        """Analyze performance test results"""
        perf_data = self.report_data.get('performance', {})
        results = perf_data.get('results', {})
        
        analysis = {
            'download_speed': 0,
            'memory_usage': 0,
            'concurrent_ops': 0,
            'performance_grade': 'Unknown',
            'bottlenecks': [],
            'recommendations': []
        }
        
        # Extract performance metrics
        if 'download_performance' in results:
            download_perf = results['download_performance']
            analysis['download_speed'] = download_perf.get('average_speed_mbps', 0)
        
        if 'memory_usage' in results:
            memory_perf = results['memory_usage']
            analysis['memory_usage'] = memory_perf.get('memory_increase_mb', 0)
        
        if 'concurrent_operations' in results:
            concurrent_perf = results['concurrent_operations']
            analysis['concurrent_ops'] = concurrent_perf.get('operations_per_second', 0)
        
        # Grade performance
        if analysis['download_speed'] > 10:
            analysis['performance_grade'] = 'Excellent'
        elif analysis['download_speed'] > 5:
            analysis['performance_grade'] = 'Good'
        elif analysis['download_speed'] > 2:
            analysis['performance_grade'] = 'Fair'
        else:
            analysis['performance_grade'] = 'Poor'
        
        # Identify bottlenecks
        if analysis['memory_usage'] > 100:
            analysis['bottlenecks'].append('High memory usage')
        
        if analysis['concurrent_ops'] < 1000:
            analysis['bottlenecks'].append('Low concurrent operation performance')
        
        # Generate recommendations
        if analysis['performance_grade'] in ['Poor', 'Fair']:
            analysis['recommendations'].append('Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±Ø¹Øª Ø¯Ø§Ù†Ù„ÙˆØ¯')
        
        if analysis['memory_usage'] > 50:
            analysis['recommendations'].append('Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡')
            
        return analysis
    
    def analyze_error_handling(self):
        """Analyze error handling test results"""
        error_data = self.report_data.get('error_handling', {})
        results = error_data.get('results', {})
        
        analysis = {
            'total_categories': len(results),
            'robust_categories': sum(1 for r in results.values() if r.get('status') == 'success'),
            'overall_robustness': 0,
            'weak_areas': [],
            'recommendations': []
        }
        
        if analysis['total_categories'] > 0:
            analysis['overall_robustness'] = (analysis['robust_categories'] / analysis['total_categories']) * 100
        
        # Identify weak areas
        for category, result in results.items():
            if result.get('status') == 'failed':
                success_rate = result.get('success_rate', 0)
                analysis['weak_areas'].append({
                    'category': category,
                    'success_rate': success_rate
                })
        
        # Generate recommendations
        if analysis['overall_robustness'] == 100:
            analysis['recommendations'].append('Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ÛŒ Ø¹Ø§Ù„ÛŒ - Ø³ÛŒØ³ØªÙ… Ø¨Ø³ÛŒØ§Ø± Ù…Ù‚Ø§ÙˆÙ…')
        elif analysis['overall_robustness'] >= 80:
            analysis['recommendations'].append('Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ÛŒ Ø®ÙˆØ¨ - Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ Ø¬Ø²Ø¦ÛŒ')
        else:
            analysis['recommendations'].append('Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ Ø¯Ø± Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§')
            
        return analysis
    
    def generate_summary_statistics(self):
        """Generate overall summary statistics"""
        # Integration tests
        integration_analysis = self.analyze_integration_tests()
        
        # Bot integration
        bot_analysis = self.analyze_bot_integration()
        
        # Performance
        performance_analysis = self.analyze_performance_tests()
        
        # Error handling
        error_analysis = self.analyze_error_handling()
        
        summary = {
            'overall_health': 'Unknown',
            'total_tests_run': (
                integration_analysis['total_tests'] + 
                bot_analysis['total_tests'] + 
                error_analysis['total_categories']
            ),
            'overall_success_rate': 0,
            'key_strengths': [],
            'areas_for_improvement': [],
            'critical_recommendations': []
        }
        
        # Calculate overall success rate
        success_rates = [
            integration_analysis['success_rate'],
            bot_analysis['success_rate'],
            error_analysis['overall_robustness']
        ]
        
        if success_rates:
            summary['overall_success_rate'] = sum(success_rates) / len(success_rates)
        
        # Determine overall health
        if summary['overall_success_rate'] >= 95:
            summary['overall_health'] = 'Excellent'
        elif summary['overall_success_rate'] >= 85:
            summary['overall_health'] = 'Good'
        elif summary['overall_success_rate'] >= 70:
            summary['overall_health'] = 'Fair'
        else:
            summary['overall_health'] = 'Poor'
        
        # Identify key strengths
        if bot_analysis['success_rate'] == 100:
            summary['key_strengths'].append('Telegram Bot Integration')
        
        if error_analysis['overall_robustness'] == 100:
            summary['key_strengths'].append('Error Handling & Recovery')
        
        if performance_analysis['performance_grade'] in ['Excellent', 'Good']:
            summary['key_strengths'].append('Download Performance')
        
        # Areas for improvement
        if integration_analysis['success_rate'] < 95:
            summary['areas_for_improvement'].append('Core Integration Stability')
        
        if performance_analysis['bottlenecks']:
            summary['areas_for_improvement'].extend(performance_analysis['bottlenecks'])
        
        # Critical recommendations
        all_recommendations = (
            integration_analysis['recommendations'] +
            bot_analysis['recommendations'] +
            performance_analysis['recommendations'] +
            error_analysis['recommendations']
        )
        
        # Prioritize unique recommendations
        summary['critical_recommendations'] = list(set(all_recommendations))
        
        return summary, integration_analysis, bot_analysis, performance_analysis, error_analysis
    
    def generate_markdown_report(self):
        """Generate comprehensive markdown report"""
        summary, integration, bot, performance, error = self.generate_summary_statistics()
        
        report = f"""# ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ ØªØ³Øª Ø³ÛŒØ³ØªÙ… Ø¯Ø§Ù†Ù„ÙˆØ¯Ø± ÛŒÙˆØªÛŒÙˆØ¨
## Final Test Report - YouTube Downloader System

**ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ø³ÛŒØ³ØªÙ…:** {summary['overall_health']}  
**Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª Ú©Ù„ÛŒ:** {summary['overall_success_rate']:.1f}%

---

## ğŸ¯ Ø®Ù„Ø§ØµÙ‡ Ø§Ø¬Ø±Ø§ÛŒÛŒ (Executive Summary)

Ø³ÛŒØ³ØªÙ… Ø¯Ø§Ù†Ù„ÙˆØ¯Ø± ÛŒÙˆØªÛŒÙˆØ¨ ØªØ­Øª {summary['total_tests_run']} ØªØ³Øª Ø¬Ø§Ù…Ø¹ Ù‚Ø±Ø§Ø± Ú¯Ø±ÙØª Ú©Ù‡ Ø´Ø§Ù…Ù„ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒØŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ØŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ Ùˆ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯.

### ğŸ† Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ú©Ù„ÛŒØ¯ÛŒ:
"""
        
        for strength in summary['key_strengths']:
            report += f"- âœ… {strength}\n"
        
        if not summary['key_strengths']:
            report += "- Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø®Ø§ØµÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯\n"
        
        report += f"""
### âš ï¸ Ù†ÙˆØ§Ø­ÛŒ Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ Ø¨Ù‡Ø¨ÙˆØ¯:
"""
        
        for improvement in summary['areas_for_improvement']:
            report += f"- ğŸ”§ {improvement}\n"
        
        if not summary['areas_for_improvement']:
            report += "- Ù‡Ù…Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ù…Ø·Ù„ÙˆØ¨\n"
        
        report += f"""
---

## ğŸ”— Ù†ØªØ§ÛŒØ¬ ØªØ³Øª ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ (Integration Tests)

**Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª:** {integration['success_rate']:.1f}%  
**ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚:** {integration['passed_tests']}/{integration['total_tests']}  
**ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚:** {integration['failed_tests']}  
**ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø±Ø¯ Ø´Ø¯Ù‡:** {integration['skipped_tests']}

### Ù…Ø³Ø§Ø¦Ù„ Ø¨Ø­Ø±Ø§Ù†ÛŒ:
"""
        
        for issue in integration['critical_issues']:
            severity_icon = "ğŸš¨" if issue['severity'] == 'high' else "âš ï¸"
            report += f"- {severity_icon} **{issue['test']}**: {issue['error']}\n"
        
        if not integration['critical_issues']:
            report += "- Ù‡ÛŒÚ† Ù…Ø³Ø¦Ù„Ù‡ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯\n"
        
        report += f"""
---

## ğŸ¤– Ù†ØªØ§ÛŒØ¬ ØªØ³Øª Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… (Bot Integration)

**Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª:** {bot['success_rate']:.1f}%  
**ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚:** {bot['passed_tests']}/{bot['total_tests']}

### Ù…Ø³Ø§Ø¦Ù„ Async:
"""
        
        for issue in bot['async_issues']:
            report += f"- ğŸ”„ {issue}\n"
        
        if not bot['async_issues']:
            report += "- Ù‡ÛŒÚ† Ù…Ø³Ø¦Ù„Ù‡ async Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯\n"
        
        report += f"""
---

## âš¡ Ù†ØªØ§ÛŒØ¬ ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ (Performance Tests)

**Ø¯Ø±Ø¬Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯:** {performance['performance_grade']}  
**Ø³Ø±Ø¹Øª Ø¯Ø§Ù†Ù„ÙˆØ¯:** {performance['download_speed']:.2f} MB/s  
**Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡:** {performance['memory_usage']:.2f} MB  
**Ø¹Ù…Ù„ÛŒØ§Øª Ù‡Ù…Ø²Ù…Ø§Ù†:** {performance['concurrent_ops']:.0f} ops/s

### Ú¯Ù„ÙˆÚ¯Ø§Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯:
"""
        
        for bottleneck in performance['bottlenecks']:
            report += f"- ğŸŒ {bottleneck}\n"
        
        if not performance['bottlenecks']:
            report += "- Ù‡ÛŒÚ† Ú¯Ù„ÙˆÚ¯Ø§Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯\n"
        
        report += f"""
---

## ğŸ›¡ï¸ Ù†ØªØ§ÛŒØ¬ ØªØ³Øª Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ (Error Handling)

**Ù…Ù‚Ø§ÙˆÙ…Øª Ú©Ù„ÛŒ:** {error['overall_robustness']:.1f}%  
**Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ù‚Ø§ÙˆÙ…:** {error['robust_categories']}/{error['total_categories']}

### Ù†ÙˆØ§Ø­ÛŒ Ø¶Ø¹ÛŒÙ:
"""
        
        for weak_area in error['weak_areas']:
            report += f"- ğŸ”´ **{weak_area['category']}**: {weak_area['success_rate']:.1f}% Ù…ÙˆÙÙ‚ÛŒØª\n"
        
        if not error['weak_areas']:
            report += "- Ù‡Ù…Ù‡ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ Ù…Ù‚Ø§ÙˆÙ…Øª Ù…Ø·Ù„ÙˆØ¨ Ø¯Ø§Ø±Ù†Ø¯\n"
        
        report += f"""
---

## ğŸ“‹ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ (Critical Recommendations)

### Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§:
"""
        
        high_priority = summary['critical_recommendations'][:3]  # Top 3 recommendations
        for i, rec in enumerate(high_priority, 1):
            report += f"{i}. ğŸ¯ {rec}\n"
        
        if len(summary['critical_recommendations']) > 3:
            report += f"\n### Ø³Ø§ÛŒØ± ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§:\n"
            for rec in summary['critical_recommendations'][3:]:
                report += f"- ğŸ’¡ {rec}\n"
        
        report += f"""
---

## ğŸ“ˆ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ù…Ø³ÛŒØ± Ø¢ÛŒÙ†Ø¯Ù‡

"""
        
        if summary['overall_health'] == 'Excellent':
            report += """ğŸ‰ **Ø³ÛŒØ³ØªÙ… Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ø¹Ø§Ù„ÛŒ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯!**

Ø³ÛŒØ³ØªÙ… Ø¯Ø§Ù†Ù„ÙˆØ¯Ø± ÛŒÙˆØªÛŒÙˆØ¨ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ø³ÛŒØ§Ø± Ù…Ø·Ù„ÙˆØ¨ÛŒ Ø§Ø² Ø®ÙˆØ¯ Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù‡ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù…Ø­ÛŒØ· ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯. ØªÙ…Ø§Ù… Ø§Ø¬Ø²Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ Ø¯Ø± Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨ÛŒ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯.
"""
        elif summary['overall_health'] == 'Good':
            report += """âœ… **Ø³ÛŒØ³ØªÙ… Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª Ø®ÙˆØ¨ÛŒ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ø¯**

Ø³ÛŒØ³ØªÙ… Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„ÛŒ Ø¯Ø§Ø±Ø¯ Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ú©ÛŒÙÛŒØªØŒ ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ù…ÙˆØ§Ø±Ø¯ Ø°Ú©Ø± Ø´Ø¯Ù‡ Ø¯Ø± Ø¨Ø§Ù„Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§ØµÙ„Ø§Ø­ Ø´ÙˆÙ†Ø¯.
"""
        elif summary['overall_health'] == 'Fair':
            report += """âš ï¸ **Ø³ÛŒØ³ØªÙ… Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¯Ø§Ø±Ø¯**

Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ù…Ø­ÛŒØ· ØªÙˆÙ„ÛŒØ¯ØŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª Ù…Ø³Ø§Ø¦Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø·Ø±Ù Ø´ÙˆÙ†Ø¯. ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø§Ø¨ØªØ¯Ø§ Ù…Ø³Ø§Ø¦Ù„ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø­Ù„ Ø´ÙˆÙ†Ø¯.
"""
        else:
            report += """ğŸš¨ **Ø³ÛŒØ³ØªÙ… Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ø²Ù†Ú¯Ø±ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø§Ø±Ø¯**

Ø³ÛŒØ³ØªÙ… Ø¯Ø± ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù†ÛŒØ³Øª. Ù„Ø§Ø²Ù… Ø§Ø³Øª ØªÙ…Ø§Ù… Ù…Ø³Ø§Ø¦Ù„ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡ Ø¨Ù‡ Ø·ÙˆØ± Ú©Ø§Ù…Ù„ Ø¨Ø±Ø·Ø±Ù Ø´ÙˆÙ†Ø¯.
"""
        
        report += f"""
### Ù…Ø±Ø§Ø­Ù„ Ø¨Ø¹Ø¯ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:

1. **Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø±ÙØ¹ Ù…Ø³Ø§Ø¦Ù„ Ø¨Ø­Ø±Ø§Ù†ÛŒ** - Ø§ÙˆÙ„ÙˆÛŒØª Ø§ÙˆÙ„
2. **Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯** - Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø±Ø¹Øª Ùˆ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ù…Ù†Ø§Ø¨Ø¹  
3. **ØªÙ‚ÙˆÛŒØª Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§** - Ø§ÙØ²Ø§ÛŒØ´ Ù…Ù‚Ø§ÙˆÙ…Øª Ø³ÛŒØ³ØªÙ…
4. **ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ** - ØªØ³Øª Ø¯Ø± Ø´Ø±Ø§ÛŒØ· ÙˆØ§Ù‚Ø¹ÛŒ Ùˆ Ø¨Ø§Ø± Ø¨Ø§Ù„Ø§
5. **Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ** - ØªÚ©Ù…ÛŒÙ„ Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙÙ†ÛŒ Ùˆ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±

---

**ğŸ“ Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø± ØªØ§Ø±ÛŒØ® {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª.**

**ğŸ” Ø¨Ø±Ø§ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±ØŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ù†ØªØ§ÛŒØ¬ ØªØ³Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ú©Ù†ÛŒØ¯.**
"""
        
        return report
    
    def save_report(self):
        """Save the final report"""
        print("\nğŸ“ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ...")
        
        # Generate markdown report
        markdown_report = self.generate_markdown_report()
        
        # Save markdown report
        with open('FINAL_TEST_REPORT.md', 'w', encoding='utf-8') as f:
            f.write(markdown_report)
        
        # Generate JSON summary
        summary, integration, bot, performance, error = self.generate_summary_statistics()
        
        json_report = {
            'report_timestamp': datetime.now().isoformat(),
            'summary': summary,
            'detailed_analysis': {
                'integration_tests': integration,
                'bot_integration': bot,
                'performance_tests': performance,
                'error_handling': error
            },
            'raw_data': self.report_data
        }
        
        # Save JSON report
        with open('final_test_report_summary.json', 'w', encoding='utf-8') as f:
            json.dump(json_report, f, ensure_ascii=False, indent=2)
        
        print("âœ… Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯:")
        print("  ğŸ“„ FINAL_TEST_REPORT.md - Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„")
        print("  ğŸ“Š final_test_report_summary.json - Ø®Ù„Ø§ØµÙ‡ JSON")
        
        return summary['overall_health'], summary['overall_success_rate']

def main():
    """Main report generation function"""
    print("ğŸš€ Ø´Ø±ÙˆØ¹ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ...")
    print("=" * 60)
    
    generator = FinalReportGenerator()
    
    # Load test results
    generator.load_test_results()
    
    # Generate and save report
    health, success_rate = generator.save_report()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ:")
    print("=" * 60)
    print(f"ğŸ¥ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…: {health}")
    print(f"ğŸ“ˆ Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª Ú©Ù„ÛŒ: {success_rate:.1f}%")
    
    if success_rate >= 90:
        print("\nğŸ‰ Ø³ÛŒØ³ØªÙ… Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯!")
        return 0
    elif success_rate >= 75:
        print("\nâš ï¸ Ø³ÛŒØ³ØªÙ… Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§ÛŒ Ø¬Ø²Ø¦ÛŒ Ø¯Ø§Ø±Ø¯")
        return 1
    else:
        print("\nğŸš¨ Ø³ÛŒØ³ØªÙ… Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ø²Ù†Ú¯Ø±ÛŒ Ø¬Ø¯ÛŒ Ø¯Ø§Ø±Ø¯")
        return 2

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)